#################################################################################
###
### Running this script to create netcdf grids with the following command:
### > python3 build_ncgrids.py -i input-escarpment.yml -o nc-escarpment -s 75
### where:
###     + input-escarpment.yml: the goSPL inputfile for a specific model
###     + nc-escarpment: a specific folder where the new grids will be saved
###     + 75: a integer representing the number of time steps to process (usually set to the number of goSPL outputs)
###
### This script will basically create similar grids as the ones done when running:
###     - exportnc.ipynb
###     - diversity.ipynb
###
### This will create 2 sets of netcdf grids for each time step:
###     1. a regular nc grid with goSPL outputs (dataXXX.nc)
###     2. a regular nc grid with morphometrics information (physioXXX.nc)
###
#################################################################################

import os
import argparse
import numpy as np
import xarray as xr
from scipy import spatial
# import metpy.calc as mpcalc
# from metpy.units import units

# import xrspatial
# from xrspatial import convolution
# from xrspatial import focal
from scripts import mapOutputs2D as mout

# Parsing command line arguments
parser = argparse.ArgumentParser(
    description="This is a simple entry to export gospl outputs to netcdf grids.", add_help=True
)
parser.add_argument("-i", "--input", help="Input file name (YAML file)", required=True)
parser.add_argument("-o", "--output", help="Output directory", required=True)
parser.add_argument("-s", "--step", help="Number of outputs to convert", required=True)

parser.add_argument(
    "-r",
    "--reso",
    help="netcdf grid resolution (m)",
    required=False,
    action="store_true",
    default=250,
)
parser.add_argument(
    "-f",
    "--flex",
    help="export flexure",
    required=False,
    action="store_true",
    default=True,
)
parser.add_argument(
    "-t",
    "--tec",
    help="export tectonic",
    required=False,
    action="store_true",
    default=False,
)

args = parser.parse_args()
if not os.path.exists(args.output):
    os.makedirs(args.output)

# Name of each netcdf output file
ncout = os.path.join(args.output, "data")

# Initialisation of the class
grid = mout.mapOutputs(path='./', filename=args.input, step=0, 
                       uplift=args.tec, flex=args.flex, model="utm")

indices = None
for k in range(0,int(args.step)+1):
    if k>0:
        # Get goSPL variables
        grid.getData(k)
        
    # Remap the variables on the regular mesh using distance weighting interpolation
    grid.buildUTMmesh(res=int(args.reso), nghb=4, smth=1)
    
    # Export corresponding regular mesh variables as netCDF file
    grid.exportNetCDF(ncfile = ncout+str(k)+'.nc')

    # Open netcdf data file for a specific time step
    # dataset = xr.open_dataset(ncout+str(k)+'.nc')
    # x = dataset.x.data
    # y = dataset.y.data
    # cellsize_x, cellsize_y = convolution.calc_cellsize(dataset.elevation)
    # dx, dy = cellsize_x, cellsize_y

    # if indices is None:
    #     xx,yy = np.meshgrid(x,y)
    #     xyz = np.zeros((len(xx.flatten()),3))
    #     xyz[:,0] = xx.ravel()
    #     xyz[:,1] = yy.ravel()
    #     tree = spatial.cKDTree(xyz, leafsize=10)
    #     indices = tree.query(xyz, k=9)[1]

    # elev = dataset.elevation.data
    # dzdy, dzdx = mpcalc.gradient(elev, deltas=(dy, dx))
    # slope_degrees = np.arctan(np.sqrt(dzdx.magnitude**2 + dzdy.magnitude**2)) * 180./np.pi

    # curv = xrspatial.curvature(dataset.elevation)
    # aspect = xrspatial.aspect(dataset.elevation)
    # hillshade = xrspatial.hillshade(dataset.elevation)

    # data_vars = {
    #         'slp_var':(['y','x'], np.nan_to_num(slope_degrees)),
    #     }
    # coords = {'y': (['y'], y), 'x': (['x'], x)}
    # physiodiv = xr.Dataset(data_vars=data_vars, coords=coords)
    # physiodiv['slp_var'].attrs = {'units':'degrees', 'long_name':'Slope in degrees',}

    # physiodiv['curvature'] = curv.copy()
    # physiodiv['aspect'] = aspect.copy()
    # physiodiv['hillshade'] = hillshade.copy()

    # cat_slp = physiodiv.slp_var.data.copy()
    # ids1 = np.where(cat_slp>=3.)
    # ids2 = np.where(np.logical_and(cat_slp<3.,cat_slp>=2.5))
    # ids3 = np.where(np.logical_and(cat_slp<2.5,cat_slp>=2.))
    # ids4 = np.where(np.logical_and(cat_slp<2.,cat_slp>=1.5))
    # ids5 = np.where(np.logical_and(cat_slp<1.5,cat_slp>=1.))
    # ids6 = np.where(np.logical_and(cat_slp<1.,cat_slp>=0.5))
    # ids7 = np.where(cat_slp<0.5)
    # cat_slp[ids7] = 1
    # cat_slp[ids6] = 2
    # cat_slp[ids5] = 3
    # cat_slp[ids4] = 4
    # cat_slp[ids3] = 5
    # cat_slp[ids2] = 6
    # cat_slp[ids1] = 7
    # physiodiv['slp_cat'] = (['y', 'x'],  cat_slp)
    # physiodiv['slp_cat'].attrs = {'units':'category', 'long_name':'Slope categorical distribution',
    #                                 'description':'Define 7 categories for continental slope based on NSEW slope values computed in degrees. Chosen values are 1: slope>3, 2: slope in [2.5,3], 3: slope in [2,2.5], 4: slope in [1.5,2], 5: slope in [1.,1.5], 6: slope in [0.5,1.] and 7: slope<0.5'}
    
    # inner_r1 = str(cellsize_x * 1)
    # outer_r1 = str(cellsize_x * 3)
    # inner_r2 = str(cellsize_x * 4)
    # outer_r2 = str(cellsize_x * 6)
    # kernel_large = convolution.annulus_kernel(cellsize_x, cellsize_y, outer_r2, inner_r2)
    # kernel_small = convolution.annulus_kernel(cellsize_x, cellsize_y, outer_r1, inner_r1)
    # focalmean_small = focal.apply(dataset.elevation, kernel_small)
    # focalmean_large = focal.apply(dataset.elevation, kernel_large)
    # tpi_small = ((dataset.elevation - focalmean_small)+0.5).astype(int)
    # tpi_large = ((dataset.elevation - focalmean_large)+0.5).astype(int)

    # # Standardize
    # tpi_small_std = ((((tpi_small-tpi_small.mean())/tpi_small.std())*100)+0.5).astype(int)
    # tpi_large_std = ((((tpi_large-tpi_large.mean())/tpi_large.std())*100)+0.5).astype(int)

    # # Classify
    # landformclass = np.zeros(tpi_small.shape)
    # flats = physiodiv.slp_var.where(physiodiv.slp_var<=0.1)
    # noflat = physiodiv.slp_var.where(physiodiv.slp_var>0.1)

    # cond1 = tpi_small_std.where((tpi_small_std>-100)&(tpi_small_std<100)&(tpi_large_std>-100)&(tpi_large_std<100))
    # cond1.data[~flats.notnull()] = np.nan
    # cond2 = tpi_small_std.where((tpi_small_std>-100)&(tpi_small_std<100)&(tpi_large_std>-100)&(tpi_large_std<100))
    # cond2.data[~noflat.notnull()] = np.nan
    # cond3 = tpi_small_std.where((tpi_small_std>-100)&(tpi_small_std<100)&(tpi_large_std>=100))
    # cond4 = tpi_small_std.where((tpi_small_std>-100)&(tpi_small_std<100)&(tpi_large_std<=-100))
    # cond5 = tpi_small_std.where((tpi_small_std<=-100)&(tpi_large_std>-100)&(tpi_large_std<100))
    # cond6 = tpi_small_std.where((tpi_small_std>=100)&(tpi_large_std>-100)&(tpi_large_std<100))
    # cond7 = tpi_small_std.where((tpi_small_std<=-100)&(tpi_large_std>=100))
    # cond8 = tpi_small_std.where((tpi_small_std<=-100)&(tpi_large_std<=-100))
    # cond9 = tpi_small_std.where((tpi_small_std>=100)&(tpi_large_std>=100))
    # cond10 = tpi_small_std.where((tpi_small_std>=100)&(tpi_large_std<=-100))

    # landformclass[cond1.notnull()] = 5
    # landformclass[cond2.notnull()] = 6
    # landformclass[cond3.notnull()] = 7
    # landformclass[cond4.notnull()] = 4
    # landformclass[cond5.notnull()] = 2
    # landformclass[cond6.notnull()] = 9
    # landformclass[cond7.notnull()] = 3
    # landformclass[cond8.notnull()] = 1
    # landformclass[cond9.notnull()] = 10
    # landformclass[cond10.notnull()] = 8

    # tpis_l = tpi_large_std.data.astype(float)
    # tpis_l[dataset.elevation.data<0.] = np.nan
    # tpis_s = tpi_small_std.data.astype(float)
    # tpis_s[dataset.elevation.data<0.] = np.nan
    # landformclass[dataset.elevation.data<0.] = np.nan
    # physiodiv['tpis_c'] = (['y', 'x'], tpis_l)
    # physiodiv['tpis_f'] = (['y', 'x'], tpis_s)
    # physiodiv['tpi_cat'] = (['y', 'x'], landformclass)
    # physiodiv['tpi_cat'].attrs = {'units':'category', 'long_name':'Landform categorical distribution',
    #                             'description':'Landform measures the topographic position of local relief normalized to local surface roughness. This is determined by calculating the topographic position index (TPI) which compares the elevation of each cell to the mean elevation of its neighborhood cells by convoluting 2 annulus kernel. The TPI is then standardized and used to define 10 landform classes (ridge, toe slope, slope, valley, open slopes...).'}

    # # Using log-scale for flow discharge
    # flow = np.nan_to_num(dataset.fillDischarge.values.copy())
    # flow[flow==0] = 0.00001
    # fill = np.log10(flow)
    # fill[fill<0] = 0.
    # physiodiv['flow'] = (['y', 'x'], fill)
    
    # catHydro = physiodiv.flow.data.copy()
    # id1 = np.where(catHydro<7)
    # id2 = np.where(np.logical_and(catHydro>=7,catHydro<8))
    # id3 = np.where(np.logical_and(catHydro>=8,catHydro<9))
    # id4 = np.where(np.logical_and(catHydro>=9,catHydro<10))
    # id5 = np.where(catHydro>=10)
    # catHydro[id1] = 1
    # catHydro[id2] = 2
    # catHydro[id3] = 3
    # catHydro[id4] = 4
    # catHydro[id5] = 5
    # physiodiv['hydro_cat'] = (['y', 'x'], catHydro)
    # physiodiv['hydro_cat'].attrs = {'units':'category', 'long_name':'Hydrology categorical distribution',
    #                         'description':'The hydrological category is based on the discharge distribution (km3/yr) obtained from the landscape evolution modelling. From the logarithmic distribution of the water flux we defined 5 categories: 1: logQs<7, 2: logQs in [7,8], 3: logQs in [8,9], 4: logQs in [9,10], 5: logQs>10.'}


    # tmpc = physiodiv.hydro_cat.data.flatten()
    # tmpc = np.nan_to_num(tmpc)
    # nonans = np.where(tmpc>0)[0]
    # prop_hydro = np.zeros(len(tmpc))

    # tmps = physiodiv.slp_cat.data.flatten()
    # tmps = np.nan_to_num(tmps)
    # prop_slp = np.zeros(len(tmps))

    # tmpt = physiodiv.tpi_cat.data.flatten()
    # tmpt = np.nan_to_num(tmpt)
    # prop_tpi = np.zeros(len(tmpt))

    # for d in range(len(nonans)):
    #     i = nonans[d]
    #     prop_hydro[i] = np.count_nonzero(tmpc[indices[i,:]]==tmpc[i])/9
    #     prop_slp[i] = np.count_nonzero(tmps[indices[i,:]]==tmps[i])/9
    #     prop_tpi[i] = np.count_nonzero(tmpt[indices[i,:]]==tmpt[i])/9

    # prop_hydro[nonans] = prop_hydro[nonans]*np.log(prop_hydro[nonans])
    # prop_slp[nonans] = prop_slp[nonans]*np.log(prop_slp[nonans])
    # prop_tpi[nonans] = prop_tpi[nonans]*np.log(prop_tpi[nonans])

    # diversity = -np.ones(len(tmpc))
    # diversity[nonans] = -(prop_hydro[nonans] + prop_slp[nonans]+prop_tpi[nonans])/np.log(3)
    # data = diversity[nonans].copy()
    # diversity[nonans] =  (data - np.min(data)) / (np.max(data) - np.min(data))
    # diversity[diversity<0] = np.nan
    # diversity = diversity.reshape(dataset.elevation.shape)
    # physiodiv['phydiv'] = (['y', 'x'], diversity)
    # physiodiv['phydiv'].attrs = {'units':'none', 'long_name':'Physiographic diversity index',
    #                     'description':'The diversity of physiographic is measured based on Shannonâ€™s equitability, which is calculated by normalizing the Shannon-Weaver diversity index. Here we use 3 categories to compute the index, namely the hydrology, landform, and slope categories.'}
   
    # physiodiv['elevation'] = dataset.elevation.copy()
    # catElev = physiodiv.elevation.data.copy()
    # id1 = np.where(catElev<100)
    # id2 = np.where(np.logical_and(catElev>=100,catElev<200))
    # id3 = np.where(np.logical_and(catElev>=200,catElev<300))
    # id4 = np.where(np.logical_and(catElev>=300,catElev<400))
    # id5 = np.where(np.logical_and(catElev>=400,catElev<500))
    # id6 = np.where(np.logical_and(catElev>=500,catElev<600))
    # id7 = np.where(np.logical_and(catElev>=600,catElev<700))
    # id8 = np.where(np.logical_and(catElev>=700,catElev<800))
    # id9 = np.where(np.logical_and(catElev>=800,catElev<900))
    # id10 = np.where(np.logical_and(catElev>=900,catElev<1000))
    # id11 = np.where(np.logical_and(catElev>=1000,catElev<1100))
    # id12 = np.where(catElev>=1100)
    # catElev[id1] = 1
    # catElev[id2] = 2
    # catElev[id3] = 3
    # catElev[id4] = 4
    # catElev[id5] = 5
    # catElev[id6] = 6
    # catElev[id7] = 7
    # catElev[id8] = 8
    # catElev[id9] = 9
    # catElev[id10] = 10
    # catElev[id11] = 11
    # catElev[id12] = 12
    # physiodiv['elev_cat'] = (['y', 'x'], catElev)
    # physiodiv['elev_cat'].attrs = {'units':'category', 'long_name':'Elevation categorical distribution',}

    # comp = dict(zlib=True, complevel=5)
    # encoding = {var: comp for var in physiodiv.data_vars}
    # physiofile = os.path.join(args.output, "physio"+str(k)+".nc")
    # physiodiv.to_netcdf(physiofile,encoding=encoding)

